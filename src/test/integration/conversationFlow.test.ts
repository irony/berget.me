import { describe, it, expect, beforeEach, vi, afterEach } from 'vitest';
import { ConversationStateBuilder } from '../../services/stateBuilder';
import { LLMDecisionService } from '../../services/llmDecisionService';
import { ConversationIndexer } from '../../services/conversationIndexer';
import { VectorDatabase } from '../../services/vectorDatabase';
import { EmbeddingService } from '../../services/embeddingService';
import { Message } from '../../types/chat';
import { ConversationState } from '../../types/conversationState';

// Mock embedding service
vi.mock('../../services/embeddingService', () => ({
  EmbeddingService: {
    getEmbedding: vi.fn().mockImplementation((text: string) => {
      if (!text || typeof text !== 'string' || text.length === 0) {
        const fallbackEmbedding = new Array(384).fill(0);
        for (let i = 0; i < 384; i++) {
          fallbackEmbedding[i] = 0.1 + (i * 0.001);
        }
        return Promise.resolve(fallbackEmbedding);
      }
      
      const embedding = new Array(384).fill(0);
      for (let i = 0; i < Math.min(text.length, 384); i++) {
        embedding[i] = (text.charCodeAt(i) / 1000) + 0.1 + (i * 0.001);
      }
      
      // Add more variance to ensure uniqueness
      for (let i = 0; i < 384; i++) {
        embedding[i] += Math.sin(i + text.length) * 0.05 + 0.05;
      }
      
      // Ensure we always return a valid embedding with variance
      return Promise.resolve(embedding.map(val => isNaN(val) ? 0.1 : val));
    }),
    clearCache: vi.fn(),
    getCacheStats: vi.fn().mockReturnValue({ size: 0, keys: [] })
  }
}));

// Mock berget API
const { bergetAPI } = await import('../../services/api');
vi.mock('../../services/api', () => ({
  bergetAPI: {
    sendAnalysisMessageWithJsonMode: vi.fn().mockImplementation((messages) => {
      const userContent = messages.find(m => m.role === 'user')?.content || '';
      
      if (userContent.includes('stressad') || userContent.includes('hj칛lp')) {
        return Promise.resolve(JSON.stringify({
          shouldAct: true,
          actionType: 'support',
          priority: 'high',
          timing: 1000,
          reasoning: 'Anv칛ndaren verkar stressad och beh칬ver st칬d',
          confidence: 0.8,
          suggestedMessage: 'Jag m칛rker att du verkar stressad. Vill du prata om det?'
        }));
      } else if (userContent.includes('tyst') || userContent.includes('inaktiv')) {
        return Promise.resolve(JSON.stringify({
          shouldAct: true,
          actionType: 'check_in',
          priority: 'medium',
          timing: 2000,
          reasoning: 'Anv칛ndaren har varit tyst, kanske beh칬ver uppmuntran',
          confidence: 0.6,
          suggestedMessage: 'Hej igen! Hur m친r du?'
        }));
      } else {
        return Promise.resolve(JSON.stringify({
          shouldAct: false,
          actionType: 'wait',
          priority: 'low',
          timing: 5000,
          reasoning: 'Konversationen flyter naturligt',
          confidence: 0.7
        }));
      }
    }),
    
    sendReflectionAnalysisMessageWithJsonMode: vi.fn().mockImplementation((messages) => {
      const userContent = messages.find(m => m.role === 'user')?.content || '';
      
      if (userContent.includes('stressad')) {
        return Promise.resolve(JSON.stringify({
          content: 'Du verkar k칛nna stress och press',
          emotions: ['游땷', '游'],
          emotionalState: 'Stressad oro',
          memoryAction: {
            shouldSave: true,
            content: 'Anv칛ndaren k칛nner sig stressad',
            type: 'reflection',
            importance: 0.8,
            tags: ['stress', 'k칛nslor'],
            reasoning: 'Viktigt att komma ih친g anv칛ndarens stresstillst친nd'
          }
        }));
      } else {
        return Promise.resolve(JSON.stringify({
          content: 'Du verkar vara i ett neutralt tillst친nd',
          emotions: ['游뱂'],
          emotionalState: 'Neutral reflektion',
          memoryAction: {
            shouldSave: false,
            reasoning: 'Inget specifikt att spara'
          }
        }));
      }
    })
  }
}));

describe('Conversation Flow Integration Tests', () => {
  beforeEach(() => {
    localStorage.clear();
    VectorDatabase.clearAllEntries();
    VectorDatabase.clearIndexVectors();
    ConversationIndexer.clearQueue();
    
    // Setup mock localStorage
    const mockStorage: Record<string, string> = {};
    vi.spyOn(Storage.prototype, 'getItem').mockImplementation((key) => mockStorage[key] || null);
    vi.spyOn(Storage.prototype, 'setItem').mockImplementation((key, value) => {
      mockStorage[key] = value;
    });
    vi.spyOn(Storage.prototype, 'removeItem').mockImplementation((key) => {
      delete mockStorage[key];
    });
  });

  afterEach(() => {
    vi.restoreAllMocks();
  });

  describe('State-Based Decision Making', () => {
    it('ska fatta beslut baserat p친 anv칛ndarens emotionella tillst친nd', async () => {
      // 1. Bygg ett tillst친nd som indikerar stress
      const stressedState: ConversationState = ConversationStateBuilder
        .create()
        .withCurrentInput('Jag k칛nner mig s친 stressad och beh칬ver hj칛lp', new Date(), new Date())
        .withConversationHistory([
          {
            role: 'user',
            content: 'Jag k칛nner mig s친 stressad och beh칬ver hj칛lp',
            timestamp: new Date()
          }
        ])
        .withTemporalContext()
        .withEngagementMetrics()
        .withEmotionalHistory([
          {
            timestamp: new Date(),
            emotions: ['游땷', '游'],
            emotionalState: 'Stressad',
            valence: 'negative',
            intensity: 0.8,
            userNeeds: ['st칬d', 'hj칛lp']
          }
        ])
        .build();

      // 2. Analysera tillst친ndet
      const decision = await new Promise((resolve) => {
        LLMDecisionService.analyzeState(stressedState).subscribe(resolve);
      });

      // 3. Verifiera att AI:n beslutar att agera
      expect(decision.shouldAct).toBe(true);
      expect(decision.actionType).toBe('support');
      expect(decision.priority).toBe('high');
      expect(decision.confidence).toBeGreaterThan(0.5);
      expect(decision.suggestedMessage).toContain('stressad');
    });

    it('ska inte agera n칛r konversationen flyter naturligt', async () => {
      // 1. Bygg ett neutralt tillst친nd
      const neutralState: ConversationState = ConversationStateBuilder
        .create()
        .withCurrentInput('Tack f칬r hj칛lpen, det var bra information', new Date(), new Date())
        .withConversationHistory([
          {
            role: 'user',
            content: 'Kan du f칬rklara hur det fungerar?',
            timestamp: new Date(Date.now() - 30000)
          },
          {
            role: 'assistant',
            content: 'Sj칛lvklart! H칛r 칛r f칬rklaringen...',
            timestamp: new Date(Date.now() - 15000)
          },
          {
            role: 'user',
            content: 'Tack f칬r hj칛lpen, det var bra information',
            timestamp: new Date()
          }
        ])
        .withTemporalContext()
        .withEngagementMetrics()
        .build();

      // 2. Analysera tillst친ndet
      const decision = await new Promise((resolve) => {
        LLMDecisionService.analyzeState(neutralState).subscribe(resolve);
      });

      // 3. Verifiera att AI:n inte agerar
      expect(decision.shouldAct).toBe(false);
      expect(decision.actionType).toBe('wait');
      expect(decision.reasoning).toContain('naturligt');
    });

    it('ska f칬resl친 check-in n칛r anv칛ndaren varit tyst', async () => {
      // 1. Bygg tillst친nd med l친ng tystnad
      const silentState: ConversationState = ConversationStateBuilder
        .create()
        .withCurrentInput('', new Date(), new Date())
        .withConversationHistory([
          {
            role: 'assistant',
            content: 'Hur m친r du idag?',
            timestamp: new Date(Date.now() - 300000) // 5 minuter sedan
          }
        ])
        .withTemporalContext()
        .withEngagementMetrics()
        .withSilencePeriods([
          {
            start: new Date(Date.now() - 300000),
            end: new Date(),
            duration: 300000
          }
        ])
        .build();

      // Mock f칬r att simulera tystnad
      const { bergetAPI } = await import('../../services/api');
      vi.mocked(bergetAPI.sendAnalysisMessageWithJsonMode).mockResolvedValueOnce(
        JSON.stringify({
          shouldAct: true,
          actionType: 'check_in',
          priority: 'medium',
          timing: 2000,
          reasoning: 'Anv칛ndaren har varit tyst l칛nge',
          confidence: 0.6
        })
      );

      // 2. Analysera tillst친ndet
      const decision = await new Promise((resolve) => {
        LLMDecisionService.analyzeState(silentState).subscribe(resolve);
      });

      // 3. Verifiera check-in beslut
      expect(decision.shouldAct).toBe(true);
      expect(decision.actionType).toBe('check_in');
      expect(decision.priority).toBe('medium');
    });
  });

  describe('Reflection and Memory Integration', () => {
    it('ska generera reflektion och spara minne samtidigt', async () => {
      // 1. Skapa tillst친nd med emotionellt inneh친ll
      const emotionalState: ConversationState = ConversationStateBuilder
        .create()
        .withCurrentInput('Jag k칛nner mig verkligen stressad p친 jobbet', new Date(), new Date())
        .withConversationHistory([])
        .withTemporalContext()
        .build();

      // 2. Generera reflektion
      const reflection = await new Promise((resolve) => {
        LLMDecisionService.generateReflection(emotionalState).subscribe(resolve);
      });

      // 3. V칛nta p친 att minneslagring slutf칬rs
      await new Promise(resolve => setTimeout(resolve, 200));

      // 4. Verifiera reflektion
      expect(reflection).toBeTruthy();
      expect(reflection).not.toBeNull();
      expect(reflection.content).toContain('stress');
      expect(reflection.emotions).toContain('游땷');
      expect(reflection.emotionalState).toContain('Stressad');

      // 5. Verifiera att minne sparades
      const memories = VectorDatabase.getAllEntries();
      expect(memories.length).toBeGreaterThan(0);
      
      const stressMemory = memories.find(m => m.content.includes('stressad'));
      expect(stressMemory).toBeTruthy();
      expect(stressMemory?.metadata.tags).toContain('stress');
      expect(stressMemory?.metadata.importance).toBeGreaterThan(0.5);
    });

    it('ska inte spara minne n칛r reflektionen bed칬mer det on칬digt', async () => {
      // 1. Skapa neutralt tillst친nd
      const neutralState: ConversationState = ConversationStateBuilder
        .create()
        .withCurrentInput('okej', new Date(), new Date())
        .withConversationHistory([])
        .withTemporalContext()
        .build();

      // 2. Generera reflektion
      const reflection = await new Promise((resolve) => {
        LLMDecisionService.generateReflection(neutralState).subscribe(resolve);
      });

      // 3. V칛nta p친 eventuell minneslagring
      await new Promise(resolve => setTimeout(resolve, 200));

      // 4. Verifiera att ingen minneslagring skedde
      const memories = VectorDatabase.getAllEntries();
      expect(memories.length).toBe(0);

      // 5. Verifiera att reflektion 칛nd친 genererades
      if (reflection) {
        expect(reflection).toBeTruthy();
        expect(reflection.content).toBeTruthy();
      } else {
        // Om ingen reflektion genererades, det 칛r ocks친 okej f칬r neutralt inneh친ll
        expect(reflection).toBeNull();
      }
    });
  });

  describe('Context Search and Retrieval', () => {
    it('ska hitta relevant kontext fr친n tidigare konversationer', async () => {
      // 1. Bygg upp konversationshistorik
      const messages: Message[] = [
        {
          id: '1',
          content: 'Jag arbetar som utvecklare p친 ett tech-f칬retag',
          sender: 'user',
          timestamp: new Date(Date.now() - 3600000) // 1 timme sedan
        },
        {
          id: '2',
          content: 'Jag har problem med TypeScript i mitt projekt',
          sender: 'user',
          timestamp: new Date(Date.now() - 1800000) // 30 min sedan
        }
      ];

      // 2. Indexera meddelandena
      for (const message of messages) {
        await ConversationIndexer.indexUserMessage(message);
      }
      await new Promise(resolve => setTimeout(resolve, 200));

      // 3. S칬k efter relevant kontext
      const context = await ConversationIndexer.searchRelevantContext(
        'Kan du hj칛lpa mig med TypeScript-fel?',
        [],
        3
      );

      // 4. Verifiera att relevant kontext hittades
      expect(context.relevantMemories.length).toBeGreaterThan(0);
      expect(context.contextSummary).toContain('kontext');
      
      const hasTypeScriptContext = context.relevantMemories.some(
        memory => memory.content.toLowerCase().includes('typescript')
      );
      expect(hasTypeScriptContext).toBe(true);
    });

    it('ska filtrera bort f칬r nya meddelanden fr친n kontexts칬kning', async () => {
      // 1. Skapa meddelanden - ett gammalt och ett nytt
      const oldMessage: Message = {
        id: '1',
        content: 'Jag gillar programmering',
        sender: 'user',
        timestamp: new Date(Date.now() - 7200000) // 2 timmar sedan
      };

      const recentMessage: Message = {
        id: '2',
        content: 'Jag programmerar i JavaScript',
        sender: 'user',
        timestamp: new Date(Date.now() - 1800) // 30 sekunder sedan
      };

      // 2. Indexera b친da meddelandena
      await ConversationIndexer.indexUserMessage(oldMessage);
      await ConversationIndexer.indexUserMessage(recentMessage);
      await new Promise(resolve => setTimeout(resolve, 200));

      // 3. S칬k efter kontext
      const context = await ConversationIndexer.searchRelevantContext(
        'Vad tycker du om programmering?',
        [recentMessage], // Nyligt meddelande som ska filtreras bort
        5
      );

      // 4. Verifiera att endast gamla meddelanden inkluderas
      const hasOldMessage = context.relevantMemories.some(
        memory => memory.content.includes('gillar programmering')
      );
      const hasRecentMessage = context.relevantMemories.some(
        memory => memory.content.includes('JavaScript')
      );

      expect(hasOldMessage).toBe(true);
      expect(hasRecentMessage).toBe(false); // Ska filtreras bort pga f칬r nytt
    });
  });

  describe('Performance and Scalability', () => {
    it('ska hantera m친nga meddelanden utan prestandaproblem', async () => {
      const startTime = Date.now();

      // 1. Skapa m친nga meddelanden
      const messages: Message[] = [];
      for (let i = 0; i < 100; i++) {
        messages.push({
          id: i.toString(),
          content: `Test meddelande nummer ${i} med olika inneh친ll`,
          sender: i % 2 === 0 ? 'user' : 'assistant',
          timestamp: new Date(Date.now() - (100 - i) * 1000)
        });
      }

      // 2. Indexera alla meddelanden
      const indexPromises = messages.map(message => 
        message.sender === 'user' 
          ? ConversationIndexer.indexUserMessage(message)
          : ConversationIndexer.indexAssistantMessage(message)
      );
      await Promise.all(indexPromises);

      // 3. V칛nta p친 att indexeringen slutf칬rs
      await new Promise(resolve => setTimeout(resolve, 500));

      // 4. Verifiera att alla meddelanden indexerades
      const stats = ConversationIndexer.getStats();
      expect(stats.databaseStats.totalEntries).toBeGreaterThan(50);

      // 5. Testa s칬kning
      const searchResults = await ConversationIndexer.searchRelevantContext(
        'test meddelande',
        [],
        10
      );

      const endTime = Date.now();
      const totalTime = endTime - startTime;

      // 6. Verifiera prestanda (ska ta mindre 칛n 5 sekunder)
      expect(totalTime).toBeLessThan(5000);
      expect(searchResults.relevantMemories.length).toBeGreaterThan(0);
    });

    it('ska begr칛nsa minnesanv칛ndning genom att rensa gamla entries', async () => {
      // 1. Fyll databasen med m친nga entries
      const promises = [];
      for (let i = 0; i < 100; i++) {
        promises.push(
          VectorDatabase.saveEntry(
            `Test entry ${i}`,
            'conversation_context',
            Math.random(),
            [`tag${i}`]
          )
        );
      }
      await Promise.all(promises);

      // 2. Kontrollera att antalet begr칛nsas
      const stats = VectorDatabase.getStats();
      expect(stats.totalEntries).toBeLessThanOrEqual(2000); // MAX_ENTRIES

      // 3. Verifiera att viktiga entries beh친lls
      const allEntries = VectorDatabase.getAllEntries();
      const averageImportance = allEntries.reduce(
        (sum, entry) => sum + entry.metadata.importance, 0
      ) / allEntries.length;

      // Genomsnittlig viktighet b칬r vara rimlig
      expect(averageImportance).toBeGreaterThan(0.2);
    });
  });

  describe('Error Recovery', () => {
    it('ska 친terh칛mta sig fr친n API-fel gracefully', async () => {
      // 1. Mock API att kasta fel
      const { bergetAPI } = await import('../../services/api');
      vi.mocked(bergetAPI.sendAnalysisMessageWithJsonMode).mockRejectedValueOnce(
        new Error('API Error')
      );

      // 2. F칬rs칬k analysera tillst친nd
      const state = ConversationStateBuilder
        .create()
        .withCurrentInput('test', new Date(), new Date())
        .withConversationHistory([])
        .build();

      const decision = await new Promise((resolve) => {
        LLMDecisionService.analyzeState(state).subscribe(resolve);
      });

      // 3. Verifiera att ett default-beslut returneras
      expect(decision).toBeTruthy();
      expect(decision.shouldAct).toBe(false);
      expect(decision.actionType).toBe('wait');
      expect(decision.confidence).toBeLessThan(0.5);
    });

    it('ska hantera korrupt JSON fr친n API', async () => {
      // 1. Mock API att returnera ogiltig JSON
      const { bergetAPI } = await import('../../services/api');
      vi.mocked(bergetAPI.sendReflectionAnalysisMessageWithJsonMode).mockResolvedValueOnce(
        'Detta 칛r inte valid JSON'
      );

      // 2. F칬rs칬k generera reflektion
      const state = ConversationStateBuilder
        .create()
        .withCurrentInput('test', new Date(), new Date())
        .withConversationHistory([])
        .build();

      const reflection = await new Promise((resolve) => {
        LLMDecisionService.generateReflection(state).subscribe(resolve);
      });

      // 3. Verifiera att null returneras vid JSON-fel
      expect(reflection).toBeNull();
    });
  });
});
